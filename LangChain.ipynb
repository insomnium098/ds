{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53cef120-7b23-4979-9760-78fa7339cffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/daniel/miniforge3/lib/python3.10/site-packages (1.11.1)\n",
      "Requirement already satisfied: langchain==0.1.5 in /Users/daniel/miniforge3/lib/python3.10/site-packages (0.1.5)\n",
      "Collecting langchain_openai\n",
      "  Obtaining dependency information for langchain_openai from https://files.pythonhosted.org/packages/a2/86/05012e5276dde3004cfb0cb383f56983d3adcb5bc8ce13ebf21ce3ea3d26/langchain_openai-0.0.5-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: tiktoken in /Users/daniel/miniforge3/lib/python3.10/site-packages (0.5.2)\n",
      "Requirement already satisfied: unstructured in /Users/daniel/miniforge3/lib/python3.10/site-packages (0.12.3)\n",
      "Requirement already satisfied: sentence-transformers in /Users/daniel/miniforge3/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: chromadb in /Users/daniel/miniforge3/lib/python3.10/site-packages (0.4.22)\n",
      "Requirement already satisfied: langchain_experimental in /Users/daniel/miniforge3/lib/python3.10/site-packages (0.0.42)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.17 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (0.0.19)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (0.1.21)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from langchain==0.1.5) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /Users/daniel/miniforge3/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: chardet in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (5.1.0)\n",
      "Requirement already satisfied: nltk in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: emoji in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (2.10.1)\n",
      "Requirement already satisfied: python-iso639 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (2024.2.7)\n",
      "Requirement already satisfied: langdetect in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (3.6.1)\n",
      "Requirement already satisfied: backoff in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: unstructured-client>=0.15.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (0.17.0)\n",
      "Requirement already satisfied: wrapt in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: onnx in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (1.15.0)\n",
      "Requirement already satisfied: pdf2image in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (20221105)\n",
      "Requirement already satisfied: pikepdf in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (8.12.0)\n",
      "Requirement already satisfied: pypdf in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (4.0.1)\n",
      "Requirement already satisfied: unstructured-inference==0.7.23 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (0.7.23)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured) (0.3.12)\n",
      "Requirement already satisfied: layoutparser[layoutmodels,tesseract] in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-inference==0.7.23->unstructured) (0.3.4)\n",
      "Requirement already satisfied: python-multipart in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-inference==0.7.23->unstructured) (0.0.7)\n",
      "Requirement already satisfied: huggingface-hub in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-inference==0.7.23->unstructured) (0.20.3)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-inference==0.7.23->unstructured) (4.9.0.80)\n",
      "Requirement already satisfied: onnxruntime<1.16 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-inference==0.7.23->unstructured) (1.15.1)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-inference==0.7.23->unstructured) (4.37.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/daniel/miniforge3/lib/python3.10/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /Users/daniel/miniforge3/lib/python3.10/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/daniel/miniforge3/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: Pillow in /Users/daniel/miniforge3/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (1.0.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (0.109.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (0.27.0.post1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (3.4.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (3.4.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (1.60.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /Users/daniel/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: packaging>=19.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/daniel/miniforge3/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.5) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.5) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
      "Requirement already satisfied: certifi in /Users/daniel/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/daniel/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/daniel/miniforge3/lib/python3.10/site-packages (from huggingface-hub->unstructured-inference==0.7.23->unstructured) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from huggingface-hub->unstructured-inference==0.7.23->unstructured) (2024.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.5) (2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/daniel/miniforge3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.4)\n",
      "Requirement already satisfied: coloredlogs in /Users/daniel/miniforge3/lib/python3.10/site-packages (from onnxruntime<1.16->unstructured-inference==0.7.23->unstructured) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/daniel/miniforge3/lib/python3.10/site-packages (from onnxruntime<1.16->unstructured-inference==0.7.23->unstructured) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /Users/daniel/miniforge3/lib/python3.10/site-packages (from onnxruntime<1.16->unstructured-inference==0.7.23->unstructured) (4.25.2)\n",
      "Requirement already satisfied: sympy in /Users/daniel/miniforge3/lib/python3.10/site-packages (from onnxruntime<1.16->unstructured-inference==0.7.23->unstructured) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.43b0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.43b0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.43b0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.1.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.5) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.5) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.5) (3.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.5) (3.0.3)\n",
      "Requirement already satisfied: networkx in /Users/daniel/miniforge3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.23->unstructured) (0.4.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: dataclasses-json-speakeasy>=0.5.11 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-client>=0.15.1->unstructured) (0.5.11)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: joblib in /Users/daniel/miniforge3/lib/python3.10/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from pdfminer.six->unstructured) (41.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from coloredlogs->onnxruntime<1.16->unstructured-inference==0.7.23->unstructured) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: pandas in /Users/daniel/miniforge3/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (1.5.3)\n",
      "Requirement already satisfied: iopath in /Users/daniel/miniforge3/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in /Users/daniel/miniforge3/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (0.10.3)\n",
      "Requirement already satisfied: pytesseract in /Users/daniel/miniforge3/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (0.3.10)\n",
      "Requirement already satisfied: torchvision in /Users/daniel/miniforge3/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (0.17.0)\n",
      "Requirement already satisfied: effdet in /Users/daniel/miniforge3/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (0.4.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from sympy->onnxruntime<1.16->unstructured-inference==0.7.23->unstructured) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /Users/daniel/miniforge3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Requirement already satisfied: timm>=0.9.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (0.9.12)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (2.0.7)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (2.3.0)\n",
      "Requirement already satisfied: portalocker in /Users/daniel/miniforge3/lib/python3.10/site-packages (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (2024.1)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (4.26.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/daniel/miniforge3/lib/python3.10/site-packages (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (4.9.3)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/daniel/miniforge3/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23->unstructured) (3.1.1)\n",
      "Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: langchain_openai\n",
      "Successfully installed langchain_openai-0.0.5\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai langchain==0.0.339 tiktoken unstructured \"unstructured[pdf]\" sentence-transformers chromadb langchain_experimental\n",
    "!pip install openai langchain==0.1.5 langchain_openai tiktoken unstructured \"unstructured[pdf]\" sentence-transformers chromadb langchain_experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cc301-984b-4fbc-a567-24c8ff107128",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce17ca6-f389-49a9-8a0d-bb972b4aaf20",
   "metadata": {},
   "source": [
    "### Añadiendo la api-key de ChatGPT y el modelo que usaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d111b86-ad28-47a1-9a6d-b99916b4b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "llm_model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829310fe-c0c0-4fdd-8414-3a7f568d2a1c",
   "metadata": {},
   "source": [
    "### Chat API : OpenAI\n",
    "Probando la conexión con OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd1e59b8-dc52-42fc-89b3-e809181a4956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x134932c20>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x134933e20>, temperature=0.0, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "# Para controlar la creatividad del LLM usaremos\n",
    "# una temperatura de = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key=OPENAI_API_KEY)\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e800854-e25e-4970-866e-6d2f478513bc",
   "metadata": {},
   "source": [
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "badfbbc4-e1b4-433a-81f0-047796524b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cuentame una broma divertida sobre gallinas.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Cuentame una broma {adjective} sobre {contenido}.\"\n",
    ").format(adjective=\"divertida\", contenido=\"gallinas\")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deae3d9f-c463-4c9f-8ed9-a5508e23ebba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Por qué la gallina cruzó la carretera?\n",
      "Para demostrarle al armadillo que no solo los pavos pueden hacerlo.\n"
     ]
    }
   ],
   "source": [
    "respuesta = chat.invoke(prompt_template)\n",
    "print(respuesta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690605bb-12fc-4808-b7a6-372a8dce3bb8",
   "metadata": {},
   "source": [
    "### Ejemplo de template para traducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7fc7aeb-4ae8-45ed-8c1a-df0b9139dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_traduccion = \"\"\"Traduce el texto \\\n",
    "que esta delimitado por triples comillas \\\n",
    "a el idioma {idioma}. \\\n",
    "texto: ```{texto}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab6831a9-e5fa-4863-be40-f140f16c7bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['idioma', 'texto'], template='Traduce el texto que esta delimitado por triples comillas a el idioma {idioma}. texto: ```{texto}```\\n')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(template_traduccion)\n",
    "prompt_template.messages[0].prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f0ebd04-6ec8-44ee-a4a8-8b700a446bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['idioma', 'texto']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1f2d1ff-9e7d-48fa-9a39-ee0d65004d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "idioma = \"español\"\n",
    "texto = \"give me the ingredients you need to bake a cake and the steps to bake a cake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fabd098e-1d09-4da0-8d9e-24ce65e73724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Traduce el texto que esta delimitado por triples comillas a el idioma español. texto: ```give me the ingredients you need to bake a cake and the steps to bake a cake```\\n')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traduccion_mensaje = prompt_template.format_messages(\n",
    "                    idioma=idioma,\n",
    "                    texto=texto)\n",
    "traduccion_mensaje\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1ba53a6-53ec-4546-8456-13b9dc402b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamando al LLM para traducir el texto a el idioma seleccionado\n",
    "mensaje_traducido = chat(traduccion_mensaje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adac081a-a2f1-41de-a58f-2910b1540749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Dame los ingredientes que necesitas para hornear un pastel y los pasos para hornear un pastel\"\n"
     ]
    }
   ],
   "source": [
    "print(mensaje_traducido.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511c07f-92a9-4c2a-88ed-21457dde863d",
   "metadata": {},
   "source": [
    "### Output parsers\n",
    "Vamos a suponer que queremos que el output del LLM tenga el siguiente formato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deefeae8-9ca8-42d5-8172-6a2a2fb849f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regalo': False, 'tiempo_de_envio': 5, 'valor': '10,000'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"regalo\": False,\n",
    "  \"tiempo_de_envio\": 5,\n",
    "  \"valor\": \"caro\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b028570-df9a-4c74-9aa2-3483630411d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_review = \"\"\"\\\n",
    "tras tener semana y media con la mochila la calidad de los materiales es buena y \n",
    "resistentes cumplió con el espacio requerido para mis necesidades como agregar \n",
    "una muda para el GYM y de paso mi portable con múltiples accesorios que requiero para mi \n",
    "trabajo ya la puse a prueba en la lluvia y si resiste lo impermiable si le \n",
    "puedo da un 9.9 por que el 10 seria la perfección y no lo es con el paso del tiempo.\n",
    "el precio fue adecuado a la calidad del producto\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "Para el siguiente texto, extrae la siguiente informacion:\n",
    "\n",
    "regalo: El producto fue comprado como un regalo para alguien mas? \\\n",
    "Responde True si es correcto, False si no o si la informacion es desconocida.\n",
    "\n",
    "tiempo_de_envio: Cuantos dias tardo el producto en llegar? \\\n",
    "Si esta informacion no esta disponible, responde con -1.\n",
    "\n",
    "valor: Extrae cualquier oracion o palabra sobre el precio del producto,\\\n",
    "y muestra el resultado como una lista de python.\n",
    "\n",
    "El resultado final debe de estar en formato de JSON con las siguientes llaves:\n",
    "regalo\n",
    "tiempo_de_envio\n",
    "valor\n",
    "\n",
    "texto: {texto}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf15fb02-1a8d-49fd-bbb4-8ea68a00488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"regalo\": false,\n",
      "  \"tiempo_de_envio\": -1,\n",
      "  \"valor\": [\"el precio fue adecuado a la calidad del producto\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "template_formato = prompt_template.format_messages(texto=texto_review)\n",
    "respuesta = chat(template_formato)\n",
    "print(respuesta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f60eb5-6d28-4cfd-8a9e-a11cfbd83874",
   "metadata": {},
   "source": [
    "## Memoria\n",
    "ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b13e569e-ade5-4918-af70-81eba507a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06397418-a967-4a61-8867-78cad6e4e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hola, mi nombre es Antonio\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hola, mi nombre es Antonio',\n",
       " 'history': '',\n",
       " 'response': '¡Hola, Antonio! ¿Cómo puedo ayudarte hoy?'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Hola, mi nombre es Antonio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "83d55eb5-0f22-4bc4-951e-0fe63571e48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hola, mi nombre es Antonio\n",
      "AI: ¡Hola, Antonio! ¿Cómo puedo ayudarte hoy?\n",
      "Human: Cual es la capital de Mexico?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Cual es la capital de Mexico?',\n",
       " 'history': 'Human: Hola, mi nombre es Antonio\\nAI: ¡Hola, Antonio! ¿Cómo puedo ayudarte hoy?',\n",
       " 'response': 'La capital de México es la Ciudad de México.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Cual es la capital de Mexico?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cde6670-14ad-4337-861c-73e2035bde17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hola, mi nombre es Antonio\n",
      "AI: ¡Hola, Antonio! ¿Cómo puedo ayudarte hoy?\n",
      "Human: Cual es la capital de Mexico?\n",
      "AI: La capital de México es la Ciudad de México.\n",
      "Human: Cual es mi nombre?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Cual es mi nombre?',\n",
       " 'history': 'Human: Hola, mi nombre es Antonio\\nAI: ¡Hola, Antonio! ¿Cómo puedo ayudarte hoy?\\nHuman: Cual es la capital de Mexico?\\nAI: La capital de México es la Ciudad de México.',\n",
       " 'response': 'Tu nombre es Antonio.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Cual es mi nombre?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aadf5b-379c-449a-8845-d7d7f16eae81",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "10f20814-57be-49e1-b7f0-5c71f20e578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.llms import OpenAI\n",
    "#memory = ConversationSummaryBufferMemory(llm=OpenAI(openai_api_key=OPENAI_API_KEY))\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    memory = ConversationSummaryMemory(llm=OpenAI(openai_api_key=OPENAI_API_KEY), memory_key=\"history\"),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c6b3d20-4a0d-4a84-9de4-af14c9dfdb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hola, mi nombre es Antonio\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hola, mi nombre es Antonio',\n",
       " 'history': '',\n",
       " 'response': '¡Hola, Antonio! ¿Cómo puedo ayudarte hoy?'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Hola, mi nombre es Antonio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b1830195-c55d-4ac8-a269-ff792f80bb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces themselves as Antonio and the AI greets them in Spanish, asking how it can help them today.\n",
      "Human: Cual es la capital de Mexico?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Cual es la capital de Mexico?',\n",
       " 'history': '\\nThe human introduces themselves as Antonio and the AI greets them in Spanish, asking how it can help them today.',\n",
       " 'response': 'La capital de México es la Ciudad de México.'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Cual es la capital de Mexico?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cf1f0-281c-42a6-88b8-dbffe5a80a8a",
   "metadata": {},
   "source": [
    "### Chains\n",
    "LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "abb8398c-999f-4e4b-a638-6e7e5c2d1b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sol y Sombra\"'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains import LLMChain\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Cual seria un buen nombre de una \\\n",
    "    empresa que fabrica {producto}?\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "producto = \"Sombrillas\"\n",
    "chain.run(producto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5856f63-9a2f-4011-9525-7c85d9f53fe5",
   "metadata": {},
   "source": [
    "SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5b5a9af-8e93-4491-9753-4286f97493bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "primer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Cual seria un buen nombre de una \\\n",
    "    empresa que fabrica {producto}?\"\n",
    ")\n",
    "primer_chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c52c1e6d-bb01-4704-b0f5-3a7ff697cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "segundo_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Dame una descripcion en 20 palabras \\\n",
    "    de una empresa con el siguiente nombre: {nombre_empresa}?\"\n",
    ")\n",
    "segundo_chain = LLMChain(llm=llm, prompt=segundo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "88c865c5-e61c-4eb5-8345-c48e71caa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "simple_chain = SimpleSequentialChain(chains=[primer_chain, segundo_chain],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cbab6a2f-5ae0-41f4-94a7-dc0ca47f5b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Sol y Sombra\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mEmpresa dedicada a la venta de productos para el cuidado de la piel y protección solar.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Empresa dedicada a la venta de productos para el cuidado de la piel y protección solar.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producto = \"Sombrillas\"\n",
    "simple_chain.run(producto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1725433-0a49-4d2f-8514-178d63e3a750",
   "metadata": {},
   "source": [
    "Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "62ed2f93-83ba-4232-96e2-c0dea9dc846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "029cf5e2-191d-446a-ac85-2adab2408960",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6e77e1f-fb23-44ab-a548-e5f97cd66c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key=OPENAI_API_KEY)\n",
    "destination_chains = {}\n",
    "\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e7280971-0fd1-4b1b-85fa-e8ca28e9f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\"\n",
    "\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "06a0012d-3453-4d0f-b4bd-8be9943efc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a227d24b-40a6-4824-baf3-9dd5b5bb7280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniforge3/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics: {'input': 'Que es la radiacion?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La radiación es la emisión de energía en forma de ondas o partículas. Puede ser natural, como la radiación solar, o artificial, como la radiación generada por dispositivos médicos o nucleares. La radiación puede ser ionizante, lo que significa que tiene suficiente energía para liberar electrones de los átomos y puede ser dañina para los tejidos vivos, o no ionizante, que tiene menos energía y generalmente no es perjudicial para los seres vivos.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_chain.run(\"Que es la radiacion?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7c9b7472-a08a-4156-bd8a-8df941f97935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniforge3/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: {'input': 'Cuanto es 100 + 5?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Gracias por tus amables palabras! La suma de 100 y 5 es igual a 105.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_chain.run(\"Cuanto es 100 + 5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66867d4a-9928-4e85-a975-5bfe52cfc115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniforge3/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: {'input': 'Que es un genoma?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Un genoma es el conjunto completo de genes o material genético presente en un organismo. Es la totalidad de la información genética que determina las características y funciones de un ser vivo. El genoma está compuesto por el ADN (ácido desoxirribonucleico) en la mayoría de los organismos, aunque en algunos virus puede estar compuesto por ARN (ácido ribonucleico). El estudio del genoma permite comprender la estructura, función y evolución de los genes, así como su relación con las enfermedades y características hereditarias.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_chain.run(\"Que es un genoma?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49128b-ccef-445e-a60f-8912e306c606",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc00d38-f39c-4bf1-a926-e293201b1a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/Users/daniel/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:11<00:00, 11.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, UnstructuredMarkdownLoader\n",
    "loader = DirectoryLoader('articulos/', glob=\"**/*.pdf\", \n",
    "                                    show_progress=True, \n",
    "                                    use_multithreading=False, \n",
    "                        )#loader_cls=UnstructuredMarkdownLoader)\n",
    "# Split documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=0)\n",
    "loader_all_splits = text_splitter.split_documents(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35e449f-ce49-4242-9b0b-9dc78fc242c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniforge3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "295fced5-002c-435e-a4d5-937e638d858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store splits\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "vectorstore_manual_pages = Chroma.from_documents(documents=loader_all_splits, \n",
    "                                                 embedding=embeddings)\n",
    "retriever_manual_pages = vectorstore_manual_pages.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1833f3fd-dd12-43e5-9f19-c1f34c851d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key=OPENAI_API_KEY)\n",
    "memory = ConversationSummaryMemory (\n",
    "    llm=llm, memory_key=\"chat_history\", return_messages=True\n",
    ")\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(llm, retriever=retriever_manual_pages, memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a46ca00c-53a3-4e2f-b9cc-3a0360e96d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Dame un resumen de los resultados del articulo',\n",
       " 'chat_history': [SystemMessage(content='')],\n",
       " 'answer': 'El artículo presenta los resultados de un estudio sobre las apuestas deportivas en el fútbol. Los investigadores analizaron datos históricos de cuotas de apuestas y llevaron a cabo pruebas en papel y apuestas reales. En general, encontraron que fue posible obtener ganancias consistentes a través de las apuestas deportivas. Los resultados mostraron un beneficio de $98,865 en los datos históricos, $34,932 en las pruebas en papel y $1,128.5 en las apuestas reales. Además, se observó un retorno del 3.5% en las pruebas en papel y del 9.9% en las apuestas reales. Estos resultados respaldan la idea de que las apuestas deportivas pueden ser una forma rentable de inversión.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Dame un resumen de los resultados del articulo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb4f15-90ad-4e90-986b-aecc3c7befa7",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3500c9-5c4c-4428-854f-0dc6f84165ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando una base de datos summy\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('credit_score')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''\n",
    "          CREATE TABLE IF NOT EXISTS users\n",
    "          ([user_name] TEXT PRIMARY KEY, [credit_score] INTEGER)\n",
    "          ''')\n",
    "          \n",
    "c.execute('''\n",
    "          CREATE TABLE IF NOT EXISTS user_reason_values \n",
    "          ([user_name] TEXT PRIMARY KEY, [reason_description] TEXT, [reason_value] TEXT)\n",
    "          ''')\n",
    "                     \n",
    "conn.commit()\n",
    "\n",
    "c.execute('''\n",
    "          INSERT INTO users (user_name, credit_score)\n",
    "\n",
    "                VALUES\n",
    "                ('Varun', 800),\n",
    "                ('Antonio', 350),\n",
    "                ('Juan', 670),\n",
    "                ('Christian',500)\n",
    "          ''')\n",
    "\n",
    "c.execute('''\n",
    "          INSERT INTO user_reason_values (user_name, reason_description, reason_value )\n",
    "\n",
    "                VALUES\n",
    "                ('Varun', 'Credit Card Utilization', '10%'),\n",
    "                ('Antonio', 'Number of Credit Lines', '25'),\n",
    "                ('Juan', 'Close Cards', '5'),\n",
    "                ('Christian','Total Debt', '100,000')\n",
    "          ''')\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "327a7483-8064-450a-9e95-719f62f117d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_name  credit_score       reason_description reason_value\n",
      "0      Varun           800  Credit Card Utilization          10%\n",
      "1    Antonio           350   Number of Credit Lines           25\n",
      "2       Juan           670              Close Cards            5\n",
      "3  Christian           500               Total Debt      100,000\n"
     ]
    }
   ],
   "source": [
    "# Probando la base de datos\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('credit_score') \n",
    "c = conn.cursor()\n",
    "                   \n",
    "c.execute('''\n",
    "          SELECT a.user_name, a.credit_score, b.reason_description, b.reason_value\n",
    "          FROM users a\n",
    "          JOIN user_reason_values b ON a.user_name = b.user_name\n",
    "          ''')\n",
    "\n",
    "df = pd.DataFrame(c.fetchall(), columns=['user_name','credit_score', 'reason_description', 'reason_value'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166fffa4-b9ac-4b07-b1e8-7395668225be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniforge3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Building the OPENAI AGENT\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///credit_score\")\n",
    "llm = OpenAI(temperature=0, verbose=True, openai_api_key=OPENAI_API_KEY, model=llm_model)\n",
    "\n",
    "#agent_executor = create_sql_agent(\n",
    "#    llm=OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY),\n",
    "#    toolkit=SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)),\n",
    "#    verbose=True,\n",
    "#    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23357e2c-7620-4303-8108-e90931e7c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983a716a-0f04-4de0-a24f-71a8ad381cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniforge3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3muser_reason_values, users\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'users'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE users (\n",
      "\tuser_name TEXT, \n",
      "\tcredit_score INTEGER, \n",
      "\tPRIMARY KEY (user_name)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from users table:\n",
      "user_name\tcredit_score\n",
      "Varun\t800\n",
      "Antonio\t350\n",
      "Juan\t670\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': \"SELECT credit_score, reason_description, reason_value FROM users WHERE user_name = 'Varun'\"}`\n",
      "responded: Based on the schema of the `users` table, I can query the `credit_score` and the reason information for Varun.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mError: (sqlite3.OperationalError) no such column: reason_description\n",
      "[SQL: SELECT credit_score, reason_description, reason_value FROM users WHERE user_name = 'Varun']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'user_reason_values'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE user_reason_values (\n",
      "\tuser_name TEXT, \n",
      "\treason_description TEXT, \n",
      "\treason_value TEXT, \n",
      "\tPRIMARY KEY (user_name)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from user_reason_values table:\n",
      "user_name\treason_description\treason_value\n",
      "Varun\tCredit Card Utilization\t10%\n",
      "Antonio\tNumber of Credit Lines\t25\n",
      "Juan\tClose Cards\t5\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': \"SELECT u.credit_score, r.reason_description, r.reason_value FROM users u JOIN user_reason_values r ON u.user_name = r.user_name WHERE u.user_name = 'Varun'\"}`\n",
      "responded: I apologize for the confusion. It seems that the `reason_description` and `reason_value` columns are actually in the `user_reason_values` table, not the `users` table. Let me correct the query for you.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(800, 'Credit Card Utilization', '10%')]\u001b[0m\u001b[32;1m\u001b[1;3mThe credit score of Varun is 800. The reason for this credit score is \"Credit Card Utilization\" with a value of 10%.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The credit score of Varun is 800. The reason for this credit score is \"Credit Card Utilization\" with a value of 10%.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corriendo una instruccion\n",
    "agent_executor.run(\n",
    "    \"Obtain the credit score, reason description and reason value of Varun\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
